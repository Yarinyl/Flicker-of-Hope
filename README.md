# Flicker of Hope (FoH): Examining the Impact of Animated Diffusion on Adversarial Patch Vulnerability

## ğŸ“˜ Overview

"Flicker of Hope" (FoH) introduces a novel defense mechanism against adversarial patch attacks on object detection systems. Unlike traditional approaches, FoH leverages an Image-to-Video (I2V) diffusion model to dynamically alter input images, thereby degrading the adversarial patchâ€™s effectiveness without modifying the underlying model.

---

## ğŸ” Core Contributions

- âœ… Model-agnostic defense that does not require training on attacked data.
- ğŸï¸ Converts static adversarial images into video frames using Stable Video Diffusion (SVD).
- ğŸ“‰ Demonstrated improved Mean Average Precision (MAP) scores compared to baseline and SAC defenses.
- ğŸ§  Proposes a new angle in adversarial defense research by animating static scenes.

---

ğŸ“„ [Read the full report here](./Flicker%20of%20Hope%20-%20Final%20Report.pdf)

---

## ğŸ› ï¸ Methodology

1. Input image xi is passed through the SVD model.
2. A short video (animation) is generated: Ai = SVD(xi).
3. A selected frame from Ai (e.g., frame 5) is passed to the object detector.
4. Predictions are made on the animated frame, not the static one.

### Architecture
```
[Static Image xi] â†’ [SVD Image-to-Video] â†’ [Selected Frame fAi] â†’ [Object Detector] â†’ [Object Predictions]
```

---

## âš™ï¸ Experimental Setup

- Dataset: MSCOCO (subset of 400 resized images, 576x1024)
- Adversarial Patch: DPatch (disappearance and illusion variants)
- Object Detector: Faster R-CNN
- Defense Baseline: Segment and Complete (SAC)
- Hardware: RTX 6000 Ada GPU

---

## ğŸ“ˆ Results Summary

| Method        | Clean | Disappearance (Adv.) | Illusion (Adv.) |
|---------------|--------|----------------------|-----------------|
| Baseline      | 0.391  | 0.140                | 0.131           |
| SAC           | 0.389  | 0.179                | 0.135           |
| FoH (Ours)    | 0.307  | 0.227                | 0.234           |

- FoH significantly outperforms SAC for Illusion attacks (p < 1e-19)
- Inference time overhead: SAC = +77 ms; FoH = +36 sec âš ï¸

---

## ğŸ”® Future Work

- Swap SVD with faster and more efficient I2V models to reduce inference time.
- Integrate temporal attention mechanisms to further refine object preservation.
- Combine FoH with segmentation-based techniques for hybrid robustness.

---

## ğŸ“‚ Repository Structure

```
.
â”œâ”€â”€ Flicker of Hope - Final Report.pdf   # Project paper
â”œâ”€â”€ README.md                            # This file
â”œâ”€â”€ src/                                 # Source code
â”‚   â”œâ”€â”€ fohtool.py                       # Main defense logic
â”‚   â””â”€â”€ utils.py                         # Utilities and metrics
â””â”€â”€ data/
    â””â”€â”€ coco_subset/                     # Evaluation dataset subset
```

---

## ğŸ‘¥ Authors

- Aviel Ben-Siman-Tov â€” avielben@post.bgu.ac.il
- Bar Dolev â€” dobar@post.bgu.ac.il
- Beni Ifland â€” ifliandb@post.bgu.ac.il
- Ido Paretsky â€” paretsky@post.bgu.ac.il
- Ken Yaggel â€” kenyag@post.bgu.ac.il
- Yarin Yerushalmi Levi â€” yarinye@post.bgu.ac.il
